{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3398,"status":"ok","timestamp":1720274941259,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"zE0HKl_TFH9N","outputId":"6277984e-5c95-43bd-ae30-72ba5b715e73"},"outputs":[],"source":["import os\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/gdrive\", force_remount=True)\n","    # cd gdrive/MyDrive/'Colab Notebooks'/Innovative-Approaches-to-Asset-Prediction/\n","    os.chdir(\"/content/gdrive/MyDrive/'Colab Notebooks'/Innovative-Approaches-to-Asset-Prediction/\")\n","    print(\"Working on Google Colab...\")\n","except:\n","    try:\n","        os.chdir(os.path.abspath(os.path.join(os.path.abspath(os.path.dirname(__vsc_ipynb_file__)), os.pardir)))\n","        print(\"Working on local machine...\")\n","    except:\n","        print(\"Can't change directory. Quitting...\")\n","        exit(1)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18653,"status":"ok","timestamp":1720274959910,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"krlsUB3HFH9R","outputId":"0e9408e9-ecdc-4936-8538-5901938b2418"},"outputs":[],"source":["# !pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import random\n","run_id = random.randint(10_000, 100_000)\n","\n","# Configuration with additional complexity\n","config = {\n","    'data_filename': 'US.RANDOM.10.5.64.3.RANGE.VOL',\n","    'data_length': 10_000,\n","    'batch_size': 128,  # Increased batch size\n","    'epochs': 200,     # Increased epochs\n","    'in_channels': 3,\n","    'output_size': 4,\n","    'conv_layers': [\n","        (16, 3, 1),\n","        (64, 3, 1),\n","        (256, 3, 1),\n","        (1024, 3, 1),\n","        (1024, 3, 1),\n","        (1024, 3, 1),\n","    ],\n","    'pool_layers': [ (2, 2), (2, 2), None, None ],\n","    'fc_layers': [256, 64],\n","    'lstm_hidden_size': 64,\n","    'lstm_layers': 1,\n","    'leak': 0.1,\n","    'dropout': 0.5,\n","    'img_size': (64, 64),\n","    'learning_rate': 1e-4,  # Adjusted learning rate for Adam\n","    'num_candles': 5,      # Number of candles to consider in sequence\n","}\n","print(f\"Run ID: {run_id}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3034,"status":"ok","timestamp":1720274962939,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"UzBmUOotMHip","outputId":"9896acf2-37b5-44f8-e83e-073e3afd57c6"},"outputs":[],"source":["import torch\n","import json\n","import numpy as np\n","import pandas as pd\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import GradScaler, autocast\n","\n","import torchvision\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","import matplotlib.pyplot as plt\n","from livelossplot import PlotLosses\n","\n","import seaborn as sns\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1720274962940,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"8NGRFdEfMSMX"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"\n","    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n","    torch.backends.cudnn.enabled = False\n","    return True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(torch.version.cuda)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1720274962940,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"GA0ElmXzFsh-","outputId":"fb819818-0fa8-4e0a-cc07-a5394bed89b8"},"outputs":[],"source":["set_seed(42)\n","\n","device = 'cpu'\n","if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n","    print(\"Cuda installed! Running on GPU!\")\n","    device = 'cuda'\n","else:\n","    print(\"No GPU available! Using CPU!\")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1720274966211,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"GkcD8eT8OAFx"},"outputs":[],"source":["from PIL import Image\n","# Custom dataset to handle image and target loading\n","class ImageSequenceDataset(Dataset):\n","    def __init__(self, images, targets, transform=None, num_candles=10):\n","        self.images = images\n","        self.targets = targets\n","        self.transform = transform\n","        self.num_candles = num_candles\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image_array = self.images[idx]\n","        target = self.targets[idx]\n","\n","        # Split the image into individual candles\n","        # Assuming the candles are equally spaced horizontally\n","        image = Image.fromarray(image_array)\n","        width, height = image.size\n","        candle_width = width // self.num_candles\n","\n","        candles = []\n","        for i in range(self.num_candles):\n","            left = i * candle_width\n","            right = left + candle_width\n","            candle_img = image.crop((left, 0, right, height))\n","\n","            if self.transform:\n","                candle_img = self.transform(candle_img)\n","            candles.append(candle_img)\n","\n","        # Stack candles to create a sequence tensor\n","        sequence = torch.stack(candles)  # Shape: (num_candles, C, H, W)\n","        return sequence, target"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1720279737884,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"ul9xbqYaOCma","outputId":"02b5b3b5-18cb-4a12-b368-396057c14cd0"},"outputs":[],"source":["# Load the data\n","filename = config[\"data_filename\"]\n","full_data = np.load(f\"./data/processed/{filename}/data.npy\", allow_pickle=True)   # noqa\n","\n","full_data = pd.DataFrame(full_data)\n","print(\"Full shape: \", full_data.shape)\n","\n","full_data = full_data.sample(n=config[\"data_length\"] if config[\"data_length\"] != None else len(full_data))\n","\n","full_data.dropna(inplace=True)\n","# min_sample = full_data[1].value_counts().min()\n","\n","# full_data = full_data.groupby(by=[1]).sample(n=min_sample, random_state=1)\n","\n","print(\"Used shape: \", full_data.shape)\n","print(full_data.head())\n","\n","# Plot the distribution of each column (except the image column)\n","for col in full_data.columns[1:]:\n","    plt.figure(figsize=(10, 6))\n","    sns.histplot(full_data[col], bins=config[\"output_size\"], kde=True)\n","    plt.title(f'Distribution of {col}')\n","    plt.xlabel(col)\n","    plt.ylabel('Frequency')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = full_data.to_numpy()\n","print(data.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","def train_val_test_split(data, train_size=0.6, val_size=0.3):\n","    # Split data into train+val and test sets\n","    train_val_data, test_data = train_test_split(data, test_size=(1 - (train_size + val_size)), random_state=42)\n","\n","    # Calculate the proportion of validation data relative to the remaining data (train + val)\n","    relative_val_size = val_size / (train_size + val_size)\n","\n","    # Split train+val into train and validation sets\n","    train_data, val_data = train_test_split(train_val_data, test_size=relative_val_size, random_state=42)\n","\n","    return train_data, val_data, test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1720279740181,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"asiDi3HGO1a-","outputId":"9206c7d7-6518-4594-e464-64396f3006c5"},"outputs":[],"source":["train_data, val_data, test_data = train_val_test_split(full_data)\n","\n","train_data = train_data.to_numpy()\n","\n","# min_sample = val_data[1].value_counts().min()\n","# val_data = val_data.groupby(by=[1]).sample(n=min_sample, random_state=1)\n","val_data = val_data.to_numpy()\n","\n","min_sample = test_data[1].value_counts().min()\n","test_data = test_data.groupby(by=[1]).sample(n=min_sample, random_state=1)\n","test_data = test_data.to_numpy()\n","\n","print(train_data.shape)\n","plt.hist(train_data[:, 1:], bins=config[\"output_size\"])\n","plt.show()\n","print(val_data.shape)\n","plt.hist(val_data[:, 1:], bins=config[\"output_size\"])\n","plt.show()\n","print(test_data.shape)\n","plt.hist(test_data[:, 1:], bins=config[\"output_size\"])\n","plt.show()\n","\n","train_images = train_data[:, 0]\n","train_targets = np.asarray(train_data[:, 1:], dtype=np.float64)\n","\n","val_images = val_data[:, 0]\n","val_targets = np.asarray(val_data[:, 1:], dtype=np.float64)\n","\n","test_images = test_data[:, 0]\n","test_targets = np.asarray(test_data[:, 1:], dtype=np.float64)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def quantize_labels(targets, num_classes=2):\n","    \"\"\"\n","    Quantize targets from the range [-1, 1] to the integer range [0, num_classes-1].\n","\n","    Args:\n","        targets (numpy.ndarray): Array of targets in the range [-1, 1].\n","        num_classes (int): Number of classes to quantize to.\n","\n","    Returns:\n","        numpy.ndarray: Quantized targets in the integer range [0, num_classes-1].\n","    \"\"\"\n","    # Scale the range from [-1, 1] to [0, 1]\n","    scaled_targets = (targets + 1) / 2\n","\n","    # Quantize to the range [0, num_classes-1]\n","    quantized_targets = np.floor(scaled_targets * (num_classes)).astype(np.int64)\n","\n","    # Ensure targets are within the range [0, num_classes-1]\n","    quantized_targets = np.clip(quantized_targets, 0, num_classes-1)\n","\n","    return quantized_targets\n","\n","plt.figure(figsize=(10, 6))\n","sns.histplot(train_targets, bins=config[\"output_size\"])\n","plt.title(f'Distribution of original range')\n","plt.xlabel(col)\n","plt.ylabel('Frequency')\n","plt.show()\n","\n","# train_targets = quantize_labels(train_targets, num_classes=config['output_size'])\n","# val_targets = quantize_labels(val_targets, num_classes=config['output_size'])\n","# test_targets = quantize_labels(test_targets, num_classes=config['output_size'])\n","\n","train_targets = train_targets.astype(np.int64)\n","val_targets = val_targets.astype(np.int64)\n","test_targets = test_targets.astype(np.int64)\n","\n","plt.figure(figsize=(10, 6))\n","sns.histplot(train_targets, bins=config[\"output_size\"])\n","plt.title(f'Distribution from 0 to {config[\"output_size\"]-1}')\n","plt.xlabel(col)\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1720279743029,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"19RIRliXV3N5"},"outputs":[],"source":["from torchvision import transforms\n","\n","# Transformations for the images\n","transform = transforms.Compose([\n","    transforms.Resize((config[\"img_size\"][0], config[\"img_size\"][1])),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,)),   # Normalize to [-1, 1]\n","])\n","\n","# Create datasets and dataloaders\n","trainset = ImageSequenceDataset(train_images, train_targets, transform=transform, num_candles=config['num_candles'])\n","valset = ImageSequenceDataset(val_images, val_targets, transform=transform, num_candles=config['num_candles'])\n","testset = ImageSequenceDataset(test_images, test_targets, transform=transform, num_candles=config['num_candles'])\n","\n","trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True)\n","valloader = DataLoader(valset, batch_size=config[\"batch_size\"], shuffle=False)\n","testloader = DataLoader(testset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def matplotlib_imshow(img, one_channel=False):\n","    if one_channel:\n","        img = img.mean(dim=0)\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    if one_channel:\n","        plt.imshow(npimg, cmap=\"Greys\")\n","    else:\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get some random training sequences\n","sequence, label = trainloader.dataset[0]\n","\n","# Show the sequence of candles\n","plt.figure(figsize=(15, 3))\n","for i in range(sequence.size(0)):\n","    plt.subplot(1, sequence.size(0), i+1)\n","    matplotlib_imshow(sequence[i])\n","    plt.axis('off')\n","plt.suptitle(f'Label: {label}')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# helper function\n","def select_n_random_sequences(dataset, n=5):\n","    '''\n","    Selects n random sequences and their corresponding labels from a dataset\n","    '''\n","    # Get n random indices\n","    rand_indices = torch.randperm(len(dataset)).tolist()[:n]\n","\n","    # Select n random sequences and labels\n","    sequences_labels = [dataset[i] for i in rand_indices]\n","\n","    return sequences_labels\n","\n","# select random sequences and their target indices\n","sequences_labels = select_n_random_sequences(trainloader.dataset, n=3)\n","\n","# plot sequences\n","for idx, (sequence, label) in enumerate(sequences_labels):\n","    plt.figure(figsize=(15, 3))\n","    for i in range(sequence.size(0)):\n","        plt.subplot(1, sequence.size(0), i+1)\n","        matplotlib_imshow(sequence[i])\n","        plt.axis('off')\n","    plt.suptitle(f'Sequence {idx+1} - Label: {label}')\n","    plt.show()"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1720279745762,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"Uckgm9R2VQxy"},"outputs":[],"source":["class FlexibleSequenceNet(nn.Module):\n","    def __init__(self, config):\n","        super(FlexibleSequenceNet, self).__init__()\n","        self.config = config\n","        self.num_candles = config['num_candles']\n","        in_channels = config['in_channels']\n","        self.cnn = nn.Sequential()\n","        layers = []\n","        for idx, (out_channels, kernel_size, padding) in enumerate(config['conv_layers']):\n","            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding))\n","            layers.append(nn.BatchNorm2d(out_channels))\n","            layers.append(nn.LeakyReLU(negative_slope=config['leak']))\n","            if idx < len(config['pool_layers']) and config['pool_layers'][idx]:\n","                layers.append(nn.MaxPool2d(kernel_size=config['pool_layers'][idx]))\n","            in_channels = out_channels\n","        self.cnn = nn.Sequential(*layers)\n","\n","        # Calculate the size of the flattened features after all convolutions and pooling layers\n","        with torch.no_grad():\n","            sample_input = torch.randn(1, config['in_channels'], *config['img_size'])\n","            conv_output = self.cnn(sample_input)\n","            self.feature_size = conv_output.view(-1).size(0)\n","\n","        # LSTM to process sequence of features\n","        self.lstm = nn.LSTM(\n","            input_size=self.feature_size,\n","            hidden_size=config['lstm_hidden_size'],\n","            num_layers=config['lstm_layers'],\n","            batch_first=True,\n","        )\n","\n","        # Fully connected layers\n","        fc_layers = []\n","        input_dim = config['lstm_hidden_size']\n","        for hidden_size in config['fc_layers']:\n","            fc_layers.append(nn.Linear(input_dim, hidden_size))\n","            fc_layers.append(nn.BatchNorm1d(hidden_size))\n","            fc_layers.append(nn.LeakyReLU(negative_slope=config['leak']))\n","            fc_layers.append(nn.Dropout(config['dropout']))\n","            input_dim = hidden_size\n","\n","        fc_layers.append(nn.Linear(input_dim, config['output_size']))\n","        self.fc_layers = nn.Sequential(*fc_layers)\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, sequence_length, channels, height, width)\n","        batch_size, seq_len, C, H, W = x.size()\n","        x = x.view(batch_size * seq_len, C, H, W)  # Merge batch and sequence dimensions\n","        x = self.cnn(x)  # Apply CNN\n","        x = x.view(batch_size, seq_len, -1)  # Reshape back to (batch_size, seq_len, feature_size)\n","        x, _ = self.lstm(x)\n","        x = x[:, -1, :]  # Get the output of the last time step\n","        x = self.fc_layers(x)\n","        x = F.log_softmax(x, dim=1)\n","        return x\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def rmse(pred, target):\n","    return torch.sqrt(torch.mean((pred - target) ** 2))\n","\n","\n","def print_examples(targets, predictions, num_examples=5):\n","    print(\"Samples (Target -> Prediction):\")\n","    for i in range(min(num_examples, len(targets))):\n","        correct = np.allclose(targets[i], predictions[i], atol=0.1)\n","        print(f\"{targets[i]} -> {predictions[i]} {'OK' if correct else ''}\")\n","    \n","    # Calculate and print relevant statistics\n","    accuracy = accuracy_score(targets, predictions)\n","    precision = precision_score(targets, predictions, average='weighted')\n","    recall = recall_score(targets, predictions, average='weighted')\n","    f1 = f1_score(targets, predictions, average='weighted')\n","\n","    print(\"\\nStatistics:\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def save_model(model: FlexibleSequenceNet, config: dict, val_accuracy: float, run_id, path='./deep_learning/models/'):\n","    # Find the pth file from the same run_id\n","    files = os.listdir(path)\n","    for file in files:\n","        if str(run_id) in file:\n","            os.remove(os.path.join(path, file))\n","\n","    torch.save(model.state_dict(), f'./deep_learning/models/{run_id}.{config[\"data_filename\"]}.{config[\"output_size\"]}.{val_accuracy*100:.0f}.pth')\n","    json.dump(config, open(f'./deep_learning/models/{run_id}.{config[\"data_filename\"]}.{config[\"output_size\"]}.{val_accuracy*100:.0f}.json', 'w'))\n","\n","    return f'{run_id}.{config[\"data_filename\"]}.{config[\"output_size\"]}.{val_accuracy*100:.0f}'"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def calculate_class_weights(targets):\n","    # Ensure targets are a 1D array\n","    targets = targets.flatten()\n","    \n","    # Count occurrences of each class\n","    class_counts = np.bincount(targets)\n","    total_samples = targets.shape[0]\n","    num_classes = len(class_counts)\n","    \n","    # Compute class weights inversely proportional to class frequencies\n","    class_weights = np.zeros(num_classes, dtype=np.float32)\n","    for i in range(num_classes):\n","        if class_counts[i] > 0:\n","            class_weights[i] = total_samples / (num_classes * class_counts[i])\n","        else:\n","            class_weights[i] = 0.0  # or assign a very high weight\n","    \n","    # Convert to PyTorch tensor\n","    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n","    \n","    return class_weights"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the model, loss function, optimizer, and scaler\n","model = FlexibleSequenceNet(config).to(device)\n","\n","# Initialize Cross Entropy Loss\n","target_weights = calculate_class_weights(train_targets).to(device)\n","print(target_weights)\n","criterion = nn.NLLLoss(weight=target_weights, reduction='mean')\n","\n","# optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)\n","\n","scaler = GradScaler()\n","\n","# Learning rate scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","# Wrap the model with DataParallel to enable multi-GPU support\n","if torch.cuda.device_count() > 1:\n","    print(f\"Using {torch.cuda.device_count()} GPUs\")\n","    print(f\"Device name: {device}\")\n","    model = nn.DataParallel(model)\n","\n","total_params = sum(\n","    param.numel() for param in model.parameters()\n",")\n","print(f'{total_params:,} total parameters.')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Training loop\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","epochs = config['epochs']\n","best_val_loss = float('inf')\n","no_improvement_epochs = 0\n","max_no_improvement_epochs = 20 # Maximum number of epochs to wait for improvement\n","min_improvement = 0.001 # Minimum improvement to reset the counter\n","\n","# Initialize livelossplot\n","liveloss = PlotLosses(outputs=['MatplotlibPlot'], groups={'Loss': ['loss', 'val_loss'], 'Accuracy': ['acc', 'val_acc'], 'Metrics': ['val_precision', 'val_recall', 'val_f1']})\n","\n","for epoch in range(epochs):\n","    logs = {}\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    \n","    for sequences, targets in trainloader:\n","        sequences, targets = sequences.to(device), targets.squeeze().to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item() * sequences.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","    \n","    train_loss = running_loss / len(trainloader.dataset)\n","    train_accuracy = correct / total\n","    \n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    all_val_targets = []\n","    all_val_predictions = []\n","    \n","    with torch.no_grad():\n","        for sequences, targets in valloader:\n","            sequences, targets = sequences.to(device), targets.squeeze().to(device)\n","            outputs = model(sequences)\n","            loss = criterion(outputs, targets)\n","            val_loss += loss.item() * sequences.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","            all_val_targets.extend(targets.cpu().numpy())\n","            all_val_predictions.extend(predicted.cpu().numpy())\n","    \n","    val_loss = val_loss / len(valloader.dataset)\n","    val_accuracy = correct / total\n","    \n","    # Calculate additional metrics\n","    val_precision = precision_score(all_val_targets, all_val_predictions, average='weighted', zero_division=0)\n","    val_recall = recall_score(all_val_targets, all_val_predictions, average='weighted', zero_division=0)\n","    val_f1 = f1_score(all_val_targets, all_val_predictions, average='weighted', zero_division=0)\n","    \n","    # Log the values\n","    logs['loss'] = train_loss\n","    logs['acc'] = train_accuracy\n","    logs['val_loss'] = val_loss\n","    logs['val_acc'] = val_accuracy\n","    logs['val_precision'] = val_precision\n","    logs['val_recall'] = val_recall\n","    logs['val_f1'] = val_f1\n","    \n","    # Send the logs to livelossplot\n","    liveloss.update(logs)\n","    liveloss.send()\n","    \n","    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","    \n","    # Print example predictions\n","    print_examples(all_val_targets, all_val_predictions, num_examples=10)\n","    \n","    # Compute and plot confusion matrix\n","    cm = confusion_matrix(all_val_targets, all_val_predictions)\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()\n","    \n","    # Step the scheduler\n","    scheduler.step()\n","    \n","    # Check for improvement\n","    if val_loss < best_val_loss - min_improvement:\n","        best_val_loss = val_loss\n","        no_improvement_epochs = 0\n","        filename = save_model(model, config, val_accuracy, run_id)\n","    else:\n","        no_improvement_epochs += 1\n","        print(f\"No improvement for {no_improvement_epochs} epochs.\")\n","    \n","    if no_improvement_epochs >= max_no_improvement_epochs:\n","        print(\"Stopping training.\")\n","        break\n","    \n","    if train_accuracy >= 0.9999:\n","        print(\"Training accuracy reached 100%.\")\n","        break\n","\n","filename = save_model(model, config, val_accuracy, run_id)\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1720280097734,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"tOi4ZK6xVXIC","outputId":"d4cc7a78-d74b-4fb1-a234-cdae7c65b25d"},"outputs":[],"source":["# Load the best model\n","# filename = f'{run_id}.{config[\"data_filename\"]}.{config[\"output_size\"]}.{val_accuracy*100:.0f}'\n","\n","print(f'Loading model: {filename}')\n","config = json.load(open(f'./deep_learning/models/{filename}.json'))\n","model = FlexibleSequenceNet(config).to(device)\n","model.load_state_dict(torch.load(f'./deep_learning/models/{filename}.pth'))\n","\n","# Test the model\n","model.eval()\n","test_loss = 0.0\n","correct = 0\n","total = 0\n","\n","all_test_targets = []\n","all_test_predictions = []\n","\n","with torch.no_grad():\n","    for sequences, targets in testloader:\n","        sequences = sequences.to(device)\n","        targets = targets.squeeze(0).to(device).long()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, targets)\n","        test_loss += loss.item() * sequences.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","        all_test_targets.extend(targets.cpu().numpy())\n","        all_test_predictions.extend(predicted.cpu().numpy())\n","\n","test_loss = test_loss / len(testloader.dataset)\n","test_accuracy = correct / total\n","\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n","\n","# Calculate additional metrics\n","test_precision = precision_score(all_test_targets, all_test_predictions, average='weighted', zero_division=0)\n","test_recall = recall_score(all_test_targets, all_test_predictions, average='weighted', zero_division=0)\n","test_f1 = f1_score(all_test_targets, all_test_predictions, average='weighted', zero_division=0)\n","\n","print(\"\\nTest Statistics:\")\n","print(f\"Precision: {test_precision:.4f}\")\n","print(f\"Recall: {test_recall:.4f}\")\n","print(f\"F1 Score: {test_f1:.4f}\")\n","\n","# Add test accuracy to txt database file\n","with open('./deep_learning/models/results.txt', 'a') as f:\n","    f.write(f'{filename}: {test_accuracy:.4f}\\n')\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
